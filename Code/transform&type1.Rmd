---
title: "Untitled"
author: "R_Boudry"
date: "5-12-2019"
output: html_document
---
######################################################
################## Robin            ##################
######################################################
Setting up data & small cleaning
```{r setup}
#Pre Explorative: glancing
##################
data <- read.csv(paste0(getwd(),"/data/armpit.txt"), sep = ' ')
data <- data[complete.cases(data),]
data$Gender <- factor(trimws(data[["Gender"]], which = c("both", "left", "right"), whitespace = "[ \t\r\n]"))
##################

#Rename the vars for readability
##################
names(data) <- c("Cb1", "Cb2", "Cb3", "Cb4", 
                 "St1", "St2", "St3", "St4",  
                 "Age", "BMI", "Gender" )
##################

```


Here we create a string variable 'top3', refering to the top 3 classes per individual.
This gives us a 26 categories for 39 individuals...
-We create top1 and top2
-Aggregate CB & ST
-Create an order based on most aggregated CB & ST: 'CBorST'

When we view the data of age and CBorST, and sort on CBorST, we see no one above 30 has CB as dominant group. First indication of change in composition
```{r}
#Create top 3 classes per observations
##################
#x <- toString(names(sort(data[1,1:8],decreasing = TRUE)[1:3]))
#top3
data$top3 <- 0
for(i in 1:nrow(data)){
  data$top3[i] <- toString(names(sort(data[i,1:8],decreasing = TRUE)[1:3]))
}
table(data$top3)
#We see 26 combinations for 39 observations.... With this data any difference
#test will seem significant.
#Let's build top 2

#top2
data$top2 <- 0
for(i in 1:nrow(data)){
  data$top2[i] <- toString(names(sort(data[i,1:8],decreasing = TRUE)[1:2]))
}
table(data$top2)
#We still see 13 categories here... Still a lot.
#Lets build top 1

#top1
data$top1 <- 0
for(i in 1:nrow(data)){
  data$top1[i] <- toString(names(sort(data[i,1:8],decreasing = TRUE)[1]))
}
table(data$top1)
#Here we have only 4 categories. However the question was composition.
#Let's aggregate Cv and ST, and then build top 2 & top 3

#aggregation
data$CB <- 0
data$ST <- 0
for(i in 1:nrow(data)){
  data$CB[i] <- sum(data[i,1:4])
  data$ST[i] <- sum(data[i,5:8])
}
par(mfrow=c(1,2))
plot(data$Age, data$CB, main = 'CB & Age')
plot(data$Age, data$ST, main = 'ST & Age')
par(mfrow=c(1,1))
#We get a hint of increase in CB, and decrease in ST, but needs testing.

#Let's build CB_ST:
#Which is dominant?
data$CBorST <- 0
for(i in 1:nrow(data)){
  data$CBorST[i] <- toString(names(sort(data[i,15:16],decreasing = TRUE)[1:2]))
}
table(data$CBorST)
#When we view the dataset, and sort on CBorST, we see no one above 30 has CB
#as dominant group. First indication of change in composition
#shown with dplyr
library(dplyr)
data%>%
  select(Age, CBorST)%>%
  filter(CBorST == "CB, ST")

##################

```


To better understand the Spearman Rank correlation significance test, we simulate
data with the same sample size (n1=n2=13) as observed.
It has to be noted that smaller sample sizes take higher correlation estimates for a significant p-value.
```{r}
p <- est <- px <- estx <- c()
for (i in 1:10000){
  Y1 <- rnorm(13)
  Y2 <- rnorm(13)
  Y1x <- rnorm(60)
  Y2x <- rnorm(60)
  p[i] <- cor.test(Y1,Y2, method = "spearman")$p.value
  est[i] <- cor.test(Y1,Y2, method = "spearman")$estimate
  px[i] <- cor.test(Y1x,Y2x, method = "spearman")$p.value
  estx[i] <- cor.test(Y1x,Y2x, method = "spearman")$estimate
}
x <- data.frame(est, p)
xx <- data.frame(estx, px)
par(mfrow=c(1,4))
plot(est, p, main = 'Correlation Estimates and \n Spearman Rank p-values \n from rnorm sampling (n1=n2=13)')
abline(h = 0.05, col = 'red')
hist(x[x$p<=0.05,1], breaks = 40, main=paste('+-', round(min(abs(x[x$p<0.05,1])),3),
     'seems to be minimum Spearman Rank \n cor value for 0.05 p-value \n (n1=n2=13)'))

plot(est, p, main = 'Correlation Estimates and \n Spearman Rank p-values \n from rnorm sampling (n1=n2=60)')
abline(h = 0.05, col = 'red')
hist(xx[xx$p<=0.05,1], breaks = 40, main=paste('+-', round(min(abs(xx[xx$p<0.05,1])),3),
     'seems to be minimum Spearman Rank \n cor value for 0.05 p-value \n (n1=n2=60)'))

par(mfrow=c(1,1))

```



Here we will sample from the uniform distribution and multiply by 100 (reflects our data)
For Type1 testing, we sample from the exact distribution
For Power testing, we limit the var1 range between .40 & .55, and create var2 by substracting var1 from 100 so they sum to 100 (as in our aggregated CB & ST).

We see the Type1 being controlled for Spearman Rank cor test, similar to more
established tests. 
The Power seems to be a lot better for Spearman Rank cor test, so much that we should compare with more non parametric tests. If this holds we should try
to understand why this test is so much more powerful while keeping Type1 controlled.
```{r}

#H0 & Power testing for our groups
#assuming an even n in groups of 13 (39/3)
#sampling from runif and *100 to reflect out data
#Working with the aggregated level of CB & ST
##################
library(coin)
results_H0_A_runif <- data.frame(size=c(rep(26,6)),dist=rep('runif',6),
                               test=rep(c('perm_t','WMW','Spearman R'),2),
                               Test=c(rep('Type1',3),rep('Power',3)),
                               Value= 0)
pt_p <- wmw_p <- spr_p <- c()
p.t <- p.wmw <- p.spr <- c()
pt_pA <- wmw_pA <- spr_pA <- c()
p.tA <- p.wmwA <- p.sprA <- c()
n <- 13
for (i in 1:10000){
  #For H0= mean from same distrib
  Y1 <- runif(n)*100
  Y2 <- runif(n)*100
  #Groups
  X <- factor (c( rep("CB",n), rep("ST",n )))
  Y <- c(Y1 , Y2)
  #Power, now we need an actual difference
  Y1x <- runif(n, min = .40, max = .55)*100
  Y2x <- 100-Y1x
  #Groups
  Xx <- factor (c( rep("CB",n), rep("ST",n )))
  Yx <- c(Y1x , Y2x)
  # permutation H0
  p.t[i] <- pvalue(oneway_test(Y ~ X,
                                distribution = approximate (B =9999)))
  p.wmw[i] <- wilcox.test(Y1 ,Y2 ,
                          exact = TRUE )$p.value
  p.spr[i] <- cor.test(Y1,Y2, method = "spearman")$p.value
  # permutation HA
  p.tA[i] <- pvalue(oneway_test(Yx ~ Xx,
                               distribution = approximate (B =9999)))
  p.wmwA[i] <- wilcox.test(Y1x ,Y2x ,
                          exact = TRUE )$p.value
  p.sprA[i] <- cor.test(Y1x,Y2x, method = "spearman")$p.value
}
# Monte - Carlo approximation of the power
# for alpha = .05
pt_p[size] <- mean(p.t < .05)
wmw_p[size] <-mean(p.wmw < .05)
spr_p[size] <-mean(p.spr < .05)  
pt_pA[size] <- mean(p.tA < .05)
wmw_pA[size] <-mean(p.wmwA < .05)
spr_pA[size] <-mean(p.sprA < .05) 

results_H0_A_runif$Value[1] <- pt_p[1]
results_H0_A_runif$Value[2] <- wmw_p[1]
results_H0_A_runif$Value[3] <- spr_p[1]
results_H0_A_runif$Value[4] <- pt_pA[1]
results_H0_A_runif$Value[5] <- wmw_pA[1]
results_H0_A_runif$Value[6] <- spr_pA[1]

library(ggplot2)
ggplot(results_H0_A_runif, aes(factor(dist), Value, fill = test)) + 
  geom_bar(stat="identity", position = "dodge") + 
  scale_fill_brewer(palette = "Greys")+
  geom_hline(yintercept=0.05, col = 'red')+
  ggtitle("Power, Type1, for 10k reps")+
  facet_grid(. ~ Test)+
  theme_classic()

#This is a similar plot, but in comment to limit output
library(gridExtra)
ggplot(results_H0_A_runif[1:3,], aes(factor(dist), Value, fill = test)) + 
  geom_bar(stat="identity", position = "dodge") + 
  scale_fill_brewer(palette = "Greys")+
  geom_hline(yintercept=0.05, col = 'red')+
  ggtitle("Type1 for 10k reps")+
  theme_classic() -> pl1

ggplot(results_H0_A_runif[4:6,], aes(factor(dist), Value, fill = test)) + 
  geom_bar(stat="identity", position = "dodge") + 
  scale_fill_brewer(palette = "Greys")+
  ggtitle("Power for 10k reps")+
  theme_classic() -> pl2

#grid.arrange(pl1, pl2, nrow = 1)
```
######################################################
######################################################


######################################################
################## Meron           ##################
######################################################
#I added only the recent codes: which i used the aggregated columns from Robin
#to better see any association 
```{r pressure, echo=FALSE}

#creat variables
data <-na.omit(data)
summary(is.na(data)) # no missing values

coryn1<-data$Corynebacterium.1
coryn2<-data$Corynebacterium.2
coryn3<-data$Corynebacterium.3
coryn4<-data$Corynebacterium.4

data$corynTot<-(coryn1+coryn2+coryn3+coryn4)
staph1<-data$Staphylococcus.1
staph2<-data$Staphylococcus.2
staph3<-data$Staphylococcus.3
staph4<-data$Staphylococcus.4
data$staphTot<-staph1+staph2+staph3+staph4
age<-data$Age

## Corynebacteria species
ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = coryn1))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = coryn2))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = coryn3))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = coryn4))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = corynTot))  #aggregating the 4 coryn genes 
                                                  #there seems a relation for some part #group of age and it is nonlinear 

cor(age,data$corynTot) ###0.476

```{r pressure, echo=FALSE}

#Staphylococcus species 

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = staph1))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = staph2))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = staph3))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = staph4))

ggplot(data = data) + 
  geom_smooth(mapping = aes(x = age, y = staphTot))

cor(age,data$staphTot)  # -0.476
```

```
######################################################
######################################################

######################################################
################## Lin              ##################
######################################################
#code
```{r pressure, echo=FALSE}

install.packages('corrgram')
install.packages('psych')
library(psych)
library(corrgram)
library(dplyr)
library(tidyr)
library(ggplot2)

# 1. Data clean and tidy

#1.1 read in data
armpit <- read.csv(file.choose(), header = TRUE, sep = ' ')

#1.2 view data
str(armpit)
summary(armpit)

#1.3 Remove observation with missing value
armpit_cleaned <- na.omit(armpit)

#1.4 Tidy variables in suitable structure
armpit_tidied <- within(armpit_cleaned,{
                        BMI <- factor(BMI)
                        Gender[Gender == "M "] <- "M"
                        Gender[Gender == "F "] <- "F"
                        Gender <- droplevels(Gender)
                        })

#1.5 Create new variables
new_armpit <- transform(armpit_tidied, Agecat = Age)
new_armpit <- within(new_armpit,{
                    Agecat[Age <= 26] <- "Junior"
                    Agecat[Age >= 27] <- "Adult"
                    Agecat[Age >= 51] <- "Senior"
                    })
new_armpit$Agecat <- factor(new_armpit$Agecat, ordered = TRUE, levels = c('Junior', 'Adult', 'Senior'))
new_armpit[1:8] <- new_armpit[1:8] /  rowSums(armpit_tidied[, 1:8])
str(new_armpit)

#2. Descriptive analysis

#2.1 Univariate fAnalysis (age, BMI, Gender, organisms)

myvars <- c('Corynebacterium.1', 'Corynebacterium.2', 'Corynebacterium.3', 'Corynebacterium.4', 'Staphylococcus.1', 'Staphylococcus.2', 'Staphylococcus.3', 'Staphylococcus.4')
describe(new_armpit[myvars])

par(mfrow=c(2,4))
for(i in (1:8)){
  name <- names(new_armpit)[i]
  boxplot(new_armpit[i], main = name)
}

par(mfrow=c(1,3))
for(i in (10:12)){
  count <- table(new_armpit[,i])
  name <- names(new_armpit)[i]
  barplot(count, main = name)
}

#2.2 Bivariate Analysis

#2.2.1 Creat a long format dataframe for analysis
new_armpit <- transform(new_armpit, organisms = names(new_armpit[1]))
long_armpit <- data.frame(new_armpit[1], new_armpit[9:13])
names(long_armpit)[1] <- 'Relative Aboundance'
for (i in 2:8){
  tem_armpit <- transform(new_armpit, organisms = names(new_armpit[i]))
  sub_armpit <- data.frame(tem_armpit[i], tem_armpit[9:13])
  names(sub_armpit)[1] <- 'Relative Aboundance'
  long_armpit <- rbind(long_armpit, sub_armpit)
}
long_armpit$organisms <- factor(long_armpit$organisms)

#2.2.2 Relative aboundance relate to agecat
ggplot(long_armpit,
       aes(x = organisms, y = `Relative Aboundance`)) + 
       geom_bar(stat = 'identity') +
       labs(title = "Raletive Aboundanc of 8 Organisms")

#2.2.3 Relative aboundance relate to agecat

describeBy(new_armpit[myvars], list(Agecat=new_armpit$Agecat))

ggplot(long_armpit,
       aes(x = organisms, y = `Relative Aboundance`, fill = Agecat)) + 
       geom_bar(stat = 'identity', position = 'fill') +
       labs(title = "Raletive Aboundanc relate to Agecat")

#2.2.4 Relative aboundance relate to BMI

describeBy(new_armpit[myvars], list(BMI=new_armpit$BMI))

ggplot(long_armpit,
       aes(x = organisms, y = `Relative Aboundance`, fill = BMI)) + 
       geom_bar(stat = 'identity', position = 'fill') +
       labs(title = "Raletive Aboundanc relate to BMI")

#2.2.5 Relative aboundance relate to gender

describeBy(new_armpit[myvars], list(Gender=new_armpit$Gender))

ggplot(long_armpit,
       aes(x = organisms, y = `Relative Aboundance`, fill = Gender)) + 
       geom_bar(stat = 'identity', position = 'dodge') +
       labs(title = "Raletive Aboundanc relate to Gender")

#2.3 Multivariate frequencies, supporting research question



#3.1 correlations in species
species <- new_armpit[1:8]
name <- c("S1", "S2", "S3", "S4", "C1", "C2", "C3", "C4")
cor_matrix <- matrix(cor(species), nrow = 8, ncol = 8,
                     dimnames = list(name, name))
cor_data <- data.frame(cor_matrix)
corrgram(cor_data, order = TRUE,
         lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt,
         main = "Corrgram of species intercorrelations")

corr.test(species)

#3.2 generate multivariate normal data
library(MASS)
set.seed(11)
mean_data <- colMeans(species)
mydata <- mvrnorm(20, mean_data, cor_matrix)
mydata <- as.data.frame(mydata)
dim(mydata)

#3.3 nonparametric multiple comparisons
kruskal.test(`Relative Aboundance`~organisms, data = long_armpit)

source('http://www.statmethods.net/RiA/wmc.txt')
wmc(`Relative Aboundance`~organisms, data = long_armpit, method = 'holm')

#4 Statistic tests


# Summary the Coryne and Staphy
new_armpit$Coryne <- 0
new_armpit$Staphy <- 0
for(i in 1:nrow(new_armpit)){
  new_armpit$Coryne[i] <- sum(new_armpit[i,1:4])
  new_armpit$Staphy[i] <- sum(new_armpit[i,5:8])
}
par(mfrow=c(1,2))
attach(new_armpit)
boxplot(Coryne~Agecat, main = 'Coryne by Agecat')
boxplot(Staphy~Agecat, main = 'Staphy by Agecat')
par(mfrow=c(1,1))

#4.1 two_sample t test
boxplot(Staphy~Gender)
boxplot(Staphy~BMI)
# H0: mean of women = mean of man (failed to reject)
t.test(Staphy~Gender)$p.value
# H0: mean of normal BMI = mean of high BMI(failed to reject)
t.test(Staphy~BMI)$p.value
# H0: means are equal among agecat
t.test(Staphy[Agecat=='Junior'], Staphy[Agecat=='Adult'])$p.value
t.test(Staphy[Agecat=='Adult'], Staphy[Agecat=='Senior'])$p.value
t.test(Staphy[Agecat=='Senior'], Staphy[Agecat=='Junior'])$p.value

#4.2 Chi-square Test
tab <- table(Gender, BMI)
barplot(tab, beside = T, legend = T)
chisq.test(tab, correct = T)


#4.3 ANOVA for multicomparison
# H0: the means are equal among agecat(Reject)
ANOVA_C <- aov(Coryne~Agecat)
summary(ANOVA_C)
ANOVA_S <- aov(Staphy~Agecat)
summary(ANOVA_S)
par(mfrow=c(1,2))
plot(TukeyHSD(ANOVA_C))
plot(TukeyHSD(ANOVA_S))
######################################################
######################################################

######################################################
################## Stijn            ##################
######################################################
#code
######################################################
######################################################
